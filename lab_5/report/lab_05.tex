\documentclass[12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
%\usepackage[14pt]{extsizes}
\usepackage{listings}

\usepackage{graphicx}
\graphicspath{{src/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\usepackage{amsmath,amsfonts,amssymb,amsthm} 

% Для листинга кода:
\lstset{ %
language=c++,                 % выбор языка для подсветки (здесь это С++)
basicstyle=\small\sffamily, % размер и начертание шрифта для подсветки кода
numbers=left,               % где поставить нумерацию строк (слева\справа)
numberstyle=\tiny,           % размер шрифта для номеров строк
stepnumber=1,                   % размер шага между двумя номерами строк
numbersep=5pt,                % как далеко отстоят номера строк от подсвечиваемого кода
showspaces=false,            % показывать или нет пробелы специальными отступами
showstringspaces=false,      % показывать или нет пробелы в строках
showtabs=false,             % показывать или нет табуляцию в строках
frame=single,              % рисовать рамку вокруг кода
tabsize=2,                 % размер табуляции по умолчанию равен 2 пробелам
captionpos=t,              % позиция заголовка вверху [t] или внизу [b] 
breaklines=true,           % автоматически переносить строки (да\нет)
breakatwhitespace=false, % переносить строки только если есть пробел
escapeinside={\#*}{*)}   % если нужно добавить комментарии в коде
}

% Для измененных титулов глав:
\usepackage{titlesec, blindtext, color} % подключаем нужные пакеты
\definecolor{gray75}{gray}{0.75} % определяем цвет
\newcommand{\hsp}{\hspace{20pt}} % длина линии в 20pt
% titleformat определяет стиль
\titleformat{\chapter}[hang]{\Huge\bfseries}{\thechapter\hsp\textcolor{gray75}{|}\hsp}{0pt}{\Huge\bfseries}


% plot
\usepackage{pgfplots}
\usepackage{filecontents}
\usetikzlibrary{datavisualization}
\usetikzlibrary{datavisualization.formats.functions}


\begin{document}
\begin{titlepage}
	\centering
	{\scshape\LARGE МГТУ им. Баумана \par}
	\vspace{3cm}
	{\scshape\Large Лабораторная работа №5\par}
	\vspace{0.5cm}	
	{\scshape\Large По курсу: "Анализ алгоритмов"\par}
	\vspace{1.5cm}
	{\huge\bfseries Конвейер \par}
	\vspace{2cm}
	\Large Работу выполнила: Серёгина Дарья, ИУ7-54Б\par
	\vspace{0.5cm}
	\LargeПреподаватели:  Волкова Л.Л., Строганов Ю.В.\par

	\vfill
	\large \textit {Москва, 2020} \par
\end{titlepage}

\tableofcontents

\newpage
\chapter*{Введение}
\addcontentsline{toc}{chapter}{Введение}
Цель работы: создать систему конвейерной обработки.

Задачи данной лабораторной работы:
\begin{enumerate}
        \item спроектировать ПО, реализующего конвейерную обработку;
        \item описать реализацию ПО;
        \item провести тестирование ПО.
\end{enumerate}



\chapter{Аналитическая часть}
В данной части будут рассмотрены главные принципы конвейерной обработки и параллельных вычислений.

\section{Общие сведения о конвейерной обработке}
\par
\textbf{Конвейер} – машина непрерывного транспорта \cite{mednov}, предназначенная для перемещения сыпучих, кусковых или штучных грузов.
\newline
\textbf{Конвейерное производство} - система поточной организации производства на основе конвейера, при которой оно разделено на простейшие короткие операции, а перемещение деталей осуществляется автоматически. Это такая организация выполнения операций над объектами, при которой весь процесс воздействия разделяется на последовательность стадий с целью повышения производительности путём одновременного независимого выполнения операций над несколькими объектами, проходящими различные стадии. Конвейером также называют средство продвижения объектов между стадиями при такой организации\cite{wiki}. Появилось в 1914 году на производстве Модели-Т на заводе Генри Форда\cite{ford} и произвело революцию сначала в автомобилестроении, а потом и во всей промышленности.

\section{Параллельное программирование}
\textbf{Параллельные вычисления} — способ организации компьютерных вычислений, при котором программы разрабатываются как набор взаимодействующих вычислительных процессов, работающих параллельно (одновременно). 

При использовании многопроцессорных вычислительных систем с общей памятью обычно предполагается, что имеющиеся в составе системы процессоры обладают равной производительностью, являются равноправными при доступе к общей памяти, и время доступа к памяти является одинаковым (при одновременном доступе нескольких процессоров к одному и тому же элементу памяти очередность и синхронизация доступа обеспечивается на аппаратном уровне). Многопроцессорные системы подобного типа обычно именуются симметричными мультипроцессорами (symmetric multiprocessors, SMP).

Перечисленному выше набору предположений удовлетворяют также активно развиваемые в последнее время многоядерные процессоры, в которых каждое ядро представляет практически независимо функциони рующее вычислительное устройство.

Обычный подход при организации вычислений для многопроцессорных вычислительных систем с общей памятью – создание новых параллельных методов на основе обычных последовательных программ, в которых или автоматически компилятором, или непосредственно программистом выделяются участки независимых друг от друга вычислений. Возможности автоматического анализа программ для порождения параллельных вычислений достаточно ограничены, и второй подход является преобладающим. При этом для разработки параллельных программ могут применяться как новые алгоритмические языки, ориентированные на параллельное программирование, так и уже имеющиеся языки, расширенные некоторым набором операторов для параллельных вычислений.

Широко используемый подход состоит и в применении тех или иных библиотек, обеспечивающих определенный программный интерфейс (application programming interface, API) для разработки параллельных программ. В рамках такого подхода наиболее известны Windows Thread API. Однако первый способ применим только для ОС семейства Microsoft Windows, а второй вариант API является достаточно трудоемким для использования и имеет низкоуровневый характер \cite{Barkalov}.

\subsection{Организация взаимодействия параллельных потоков}
Потоки исполняются в общем адресном пространстве параллельной программы. Как результат, взаимодействие параллельных потоков можно организовать через использование общих данных, являющихся доступными для всех потоков. Наиболее простая ситуация состоит в использовании общих данных только для чтения. В случае же, когда общие данные могут изменяться несколькими потоками, необходимы специальные усилия для организации правильного взаимодействия.

\section{Вывод}
В данном разделе были рассмотрены основы конвейерной обработки, технология параллельного программирования и
организация взаимодействия параллельных потоков.



\chapter{Конструкторская часть}
\textbf{Требования к вводу:}
Количество конвейеров должно быть больше 0.
\newline
\textbf{Требования к программе при параллельной обработке:}
\begin{itemize}
\item Объекты должны последовательно проходить конвейеры в заданном подядке;
\item конвейеры должны работать каждый в своем потоке;
\item конвейер должен завершать свою работу при поступлении специального элемента;
\item до завершения работы конвейер должен ожидать поступления новых элементов.
\end{itemize}

\section{Организация обработки}
У каждой линии конвейера есть очередь элементов. Когда линия еще активна, но элементов в очереди нет, линия уходит в режим ожидания.
По прошествию заданного времени линия проверяет не появились ли новые элементы в очереди. Если очередь не пустая, то нужно получить и обработать элемент, передать его следующей линии, если такая существует.

\section{Вывод}
В данном разделе была рассмотрена схема организации конвейерной обработки.

 

\chapter{Технологическая часть}
Замеры времени были произведены на: Intel(R) Core(TM) i5-8300H, 4 ядра, 8 логических процессоров.

\section{Выбор ЯП}
В качестве языка программирования был выбран C++ \cite{Microsoft}, так как этот
язык поддерживает управление потоками на уровне ОС. Средой разработки Visual Studio. 
Для измерения процессорного времени была взята функция
rdtsc из библиотеки ctime.

\section{Листинг кода алгоритмов}

\begin{lstlisting}[label=some-code,caption=Код программы]
class Conveyor {
	private:
	size_t elementsCount;
	size_t queuesCount;
	size_t averegeTime;
	const size_t delayTime = 3;
	
	size_t getCurTime() {
		return std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::steady_clock::now().time_since_epoch()).count();
	}
	
	void doObjectLinearWork(matrixObject& curObject, size_t queueNum) {
		size_t start = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": START - " << start << endl;
		
		curObject.addUpMatrix(0, curObject.sizeMatrix/3);
		
		size_t end = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": STOP -  " << end << endl;
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": TIME -  " << end - start << endl;
	}
	
	void doObjectLinearWork2(matrixObject& curObject, size_t queueNum) {
		size_t start = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": START - " << start << endl;
		
		curObject.addUpMatrix(curObject.sizeMatrix / 3, 2 * curObject.sizeMatrix / 3);
		
		size_t end = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": STOP -  " << end << endl;
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": TIME -  " << end - start << endl;
	}
	
	void doObjectLinearWork3(matrixObject& curObject, size_t queueNum) {
		size_t start = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": START - " << start << endl;
		
		curObject.addUpMatrix(2 * curObject.sizeMatrix / 3, curObject.sizeMatrix);
		
		size_t end = getCurTime();
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": STOP -  " << end << endl;
		//        cout << "Object #" << curObject.number <<  " from Queue #" << queueNum << ": TIME -  " << end - start << endl;
		//resTimeFile
	}
	
	public:
	Conveyor(size_t elementsCount, size_t queuesCount, size_t milliseconds) : elementsCount(elementsCount), queuesCount(queuesCount), averegeTime(milliseconds) {}
	
	void executeLinear() {
		
		queue <matrixObject> objectsGenerator;
		
		for (size_t i = 0; i < elementsCount; ++i) {
			objectsGenerator.push(matrixObject(1038, -20, 200, i + 1));
		}
		
		vector <matrixObject> objectsPool;
		
		while (objectsPool.size() != elementsCount) {
			matrixObject curObject = objectsGenerator.front();
			objectsGenerator.pop();
			
			for (size_t i = 0; i < queuesCount; ++i) {
				if (i == 0) {
					doObjectLinearWork(curObject, i);
				} else if (i == 1) {
					doObjectLinearWork2(curObject, i);
				} else if (i >= 2) {
					doObjectLinearWork3(curObject, i);
				}
				
			}
			
			objectsPool.push_back(curObject);
		}
	}
	
	private:
	void doObjectParallelWork(matrixObject curObject, queue <matrixObject>& queue, size_t queueNum, mutex& mutex) {
		size_t start = getCurTime();
		
		curObject.addUpMatrix(0, curObject.sizeMatrix/3);
		
		mutex.lock();
		queue.push(curObject);
		mutex.unlock();
		
		size_t end = getCurTime();
		//        cout << "Object" << curObject.number <<  "; Queue " << queueNum << "; Time  " << end - start << endl;
		objectTimeStayingAtQueue[queueNum + 1].push_back(-end);
	}
	
	void doObjectParallelWork1(matrixObject curObject, queue <matrixObject>& queue, size_t queueNum, mutex& mutex) {
		size_t start = getCurTime();
		curObject.addUpMatrix(curObject.sizeMatrix / 3, 2 * curObject.sizeMatrix / 3);
		
		mutex.lock();
		queue.push(curObject);
		mutex.unlock();
		
		size_t end = getCurTime();
		//        cout << "Object" << curObject.number <<  "; Queue " << queueNum << "; Time  " << end - start << endl;
		objectTimeStayingAtQueue[queueNum + 1].push_back(-end);
	}
	
	void doObjectParallelWork2(matrixObject curObject, queue <matrixObject>& queue, size_t queueNum, mutex& mutex) {
		size_t start = getCurTime();
		
		curObject.addUpMatrix(2 * curObject.sizeMatrix / 3, curObject.sizeMatrix);
		
		mutex.lock();
		queue.push(curObject);
		mutex.unlock();
		
		size_t end = getCurTime();
		//        cout << "Object" << curObject.number <<  "; Queue " << queueNum << "; Time  " << end - start << endl;
		objectTimeStayingAtQueue[queueNum + 1].push_back(-end);
	}
	
	public:
	void executeParallel() {
		
		queue <matrixObject> objectsGenerator;
		
		for (size_t i = 0; i < elementsCount; ++i) {
			objectsGenerator.push(matrixObject(1038, -20, 200, i + 1));
		}
		
		vector <thread> threads(3);
		vector <queue <matrixObject> > queues(3);
		queue <matrixObject> objectsPool;
		vector <mutex> mutexes(4);
		size_t prevTime = getCurTime() - delayTime;
		
		while (objectsPool.size() != elementsCount) {
			size_t curTime = getCurTime();
			
			if (!objectsGenerator.empty() && prevTime + delayTime < curTime) {
				matrixObject curObject = objectsGenerator.front();
				objectsGenerator.pop();
				queues[0].push(curObject);
				
				prevTime = getCurTime();
				
				objectTimeStayingAtQueue[0].push_back(-prevTime);
			}
			
			for (int i = 0; i < queuesCount; ++i) {
				if (threads[i].joinable()) {
					threads[i].join();
				}
				if (!queues[i].empty() && !threads[i].joinable()) {
					mutexes[i].lock();
					matrixObject curObject = queues[i].front();
					queues[i].pop();
					mutexes[i].unlock();
					
					size_t start = getCurTime();
					objectTimeStayingAtQueue[i][objectTimeStayingAtQueue[i].size() - 1] += start;
					
					if (i == 0) {
						threads[i] = thread(&Conveyor::doObjectParallelWork, this, curObject, ref(queues[i + 1]), i, ref(mutexes[i + 1]));
					} else if (i == 1) {
						threads[i] = thread(&Conveyor::doObjectParallelWork1, this, curObject, ref(queues[i + 1]), i, ref(mutexes[i + 1]));
					} else if (i == queuesCount - 1) {
						threads[i] = thread(&Conveyor::doObjectParallelWork2, this, curObject, ref(objectsPool), i, ref(mutexes[i + 1]));
						
					}
				}
			}
		}
		
		for (int i = 0; i < queuesCount; ++i) {
			if (threads[i].joinable()) {
				threads[i].join();
			}
		}
	}
	
};
\end{lstlisting}

\section{Вывод}
В данном разделе были рассмотрены основные сведения о модулях программы, листинг кода.


\chapter{Исследовательская часть}

\section{Сравнительный анализ на основе замеров времени}

Был проведен замер времени работы конвейерной и линейной обработки при разных временах обработки одной линии.
 
\begin{tikzpicture}
\begin{axis}[
    	axis lines = left,
    	xlabel = {Максимальныая задержка(мс)},
    	ylabel = {Время (тики)},
	legend pos=north west,
	ymajorgrids=true
]


\addplot[color=yellow, mark=square] table[x index=0, y index= 1] {src/dataParallel.txt}; 
\addplot[color=orange, mark=square] table[x index=0, y index= 1] {src/dataLinear.txt}; 
\addplot[color=purple, mark=square] table[x index=0, y index= 1] {src/dataFullLinear.txt}; 


\addlegendentry{Паралельный}
\addlegendentry{Линейный}
\addlegendentry{Полностью линейный}

\end{axis}
\end{tikzpicture}
\begin{center}
Pис. 4.1: Сравнение времени работы при разных дельтах зедержек
\end{center}


На графиках видно, что конвейерная обработка с параллельными потоками в 2.5 раза быстрее чем такая же линейная с захватом переменных.
Если же убрать ненужные захваты переменных (т.к. все действия происходят линейно, не может быть одновременного обращения к одной области памяти), то это будет работать в 2.5 раза быстрее, чем параллельный.

\section{Тестирование}
Для тестирования был выведен лог операций в формате : 
id конвейера; id элемента; состояние; время

\begin{figure}[h]
	\center{\includegraphics[scale = 0.7]{src/allDataTogether.png}}
	\caption{Лог работы конвейерной обработки}
	\label{fig:v_st}
\end{figure}



\section{Вывод}
По результатам исследования конвейерную обработку нет смысла применять для задач, занимающих мало времени, т.к. в этом случее большая часть времени
потратится на ожидание доступа к переменной, дополнительных проверок.
Тестирование показало, что конвейерная обработка реализована правильно.

\chapter*{Заключение}
\addcontentsline{toc}{chapter}{Заключение}
В ходе лабораторной работы я изучила возможности применения параллельных вычислений и конвейерной обработки и использовала такой подход на практике. 

Был проведен эксперимент с разными дельтами задержек, который показал что если первый конвейер тормозит работу, то общее время работы системы
линейно от задержки первого конвейера. Также этот эксперимент показал, что конвейерную обработку нет смысла применять для задач, занимающих мало времени, т.к. в этом случее большая часть времени потратится на ожидание доступа к переменной, дополнительных проверок.

Конвейерная обработка позволяет сильно ускорить программу, если требуется обработать набор из однотипных данных, причем алгоритм обработки должен быть разбиваем на стадии. Однако от конвейерной обработки не будет смысла, если одна из стадий намного более трудоемкая, чем остальные, так как производительность всей программы будет упираться в производительность этой самой стадии, и разницы между обычной обработкой и конвейерной не будет, только добавятся накладные вычисления, связанные с диспетчеризацией потоков. В таком случае можно либо разбить трудоемкую стадию на набор менее трудоемких, либо выбрать другой алгоритм, либо отказаться от конвейерной обработки.

\addcontentsline{toc}{chapter}{Список литературы}
 \begin{thebibliography}{3}
\bibitem{mednov} Меднов В.П., Бондаренко Е.П. Транспортные, распределительные и рабочие конвейеры. М., 1970.
\bibitem{wiki} Конвейерное производство[Электронный ресурс] - режим доступа https:/ё/dic.academic.ru/dic.nsf/ruwiki/1526795
\bibitem{ford} Koнвeйepный meтoд пpoизвoдcтвa Гeнpи Фopдa[Электронный ресурс] - режим доступа https://popecon.ru/305-konveiernyi-metod-proizvodstva-genri-forda.html
\bibitem{Beloysov} И. В. Белоусов(2006), Матрицы и определители, учебное пособие по линейной алгебре, с. 1 - 16
\bibitem{Barkalov} Константин Баркалов, Владимир Воеводин, Виктор Гергель. Intel Parallel Programming [Электронный ресурс], - режим доступа https://www.intuit.ru/studies/courses/4447/983/lecture/14925
\bibitem{Beloysov}
И. В. Белоусов(2006), Матрицы и определители, учебное пособие по линейной алгебре, с. 1 - 16
\bibitem{Gall2012}
Le Gall, F. (2012), "Faster algorithms for rectangular matrix multiplication", Proceedings of the 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS 2012), pp. 514–523
%https://arxiv.org/pdf/1204.1111.pdf
\bibitem{Barkalov}
Константин Баркалов, Владимир Воеводин, Виктор Гергель. Intel Parallel Programming [Электронный ресурс], - режим доступа https://www.intuit.ru/studies/courses/4447/983/lecture/14925
\end{thebibliography}


\end{document}